# StyleCycleGAN

(Personal MSc Project)

## Utilizing massively pretrained CLIP and DALL-E models to achieve efficient and low-data unsupervised domain translation

Architecture: \
![image](https://github.com/SS-YuJJ/StyleCycleGAN/blob/main/pics/model_architecture.png) \


Results of autoencoder when using different layers of CLIP embedding: \
![image](https://github.com/SS-YuJJ/StyleCycleGAN/blob/main/pics/autoencoder_diff_CLIPlayers.png)

Results when different modules are used as pre-trained or not, fine-tuned or fixed during training: \
![image](https://github.com/SS-YuJJ/StyleCycleGAN/blob/main/pics/diff_train_setting.png)
